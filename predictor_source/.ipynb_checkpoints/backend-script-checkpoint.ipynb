{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import grad as torch_grad\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.misc import derivative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def sliding_window(x, y, y_raw ,feature_window,label_window,trend_window):\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "    y_gan_pr = []\n",
    "    y_gan_cl = []\n",
    "    y_gan_tr = []\n",
    "    backward_length = max(trend_window,label_window)\n",
    "    for i in range(backward_length, x.shape[0]-label_window):\n",
    "        tmp_x = x[i - feature_window: i, :]\n",
    "        tmp_y = y[i]\n",
    "        tmp_y_gan_pr = y[i - feature_window: i + 1]\n",
    "        tmp_y_gan_cl = y_raw[i - label_window: i + label_window+1]\n",
    "        tmp_y_gan_tr = y_raw[i - trend_window: i, :]\n",
    "        x_.append(tmp_x)\n",
    "        y_.append(tmp_y)\n",
    "        y_gan_pr.append(tmp_y_gan_pr)\n",
    "        y_gan_cl.append(tmp_y_gan_cl)\n",
    "        y_gan_tr.append(tmp_y_gan_tr)\n",
    "    x_ = torch.from_numpy(np.array(x_)).float()\n",
    "    y_ = torch.from_numpy(np.array(y_)).float()\n",
    "    # print(y_gan_cl.shape)\n",
    "    # print(type(y_gan_cl))\n",
    "    y_gan_pr = torch.from_numpy(np.array(y_gan_pr)).float()\n",
    "    y_gan_cl = np.array(y_gan_cl)\n",
    "    y_gan_cl = y_gan_cl.astype(np.float64)\n",
    "    y_gan_cl = torch.from_numpy(np.array(y_gan_cl)).float()\n",
    "    y_gan_tr = np.array(y_gan_tr)\n",
    "    y_gan_tr = y_gan_tr.astype(np.float64)\n",
    "    y_gan_tr = torch.from_numpy(np.array(y_gan_tr)).float()\n",
    "    return x_, y_, y_gan_pr,y_gan_cl,y_gan_tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3980768800.py, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 43\u001b[1;36m\u001b[0m\n\u001b[1;33m    return torch.from_numpy(mean_derivatives)mean_derivatives)\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# def trend_detection(data):\n",
    "#     n = data.shape[1]\n",
    "#     sets = data.shape[0]\n",
    "#     mean_derivatives = np.zeros((sets,1))\n",
    "    \n",
    "#     data = data.numpy()\n",
    "\n",
    "#     for i in range(sets):\n",
    "#         # Select the i-th 20 set\n",
    "#         x = np.arange(1,n+1)\n",
    "#         x_fake = np.arange(1.1, n, 0.1)\n",
    "#         y = data[i, :, 0]\n",
    "#         # Simple interpolation of x and y    \n",
    "#         f = interp1d(x, y)\n",
    "        \n",
    "#         # derivative of y with respect to x\n",
    "#         df_dx = nd.Derivative(f, step=1e-6)(x_fake)\n",
    "#         # Calculate the mean derivative for the i-th 20 set\n",
    "#         average = np.average(df_dx)\n",
    "#         mean_derivatives[i][0] = average\n",
    "#     return  torch.from_num\n",
    "\n",
    "def trend_detection(data):\n",
    "    n = data.shape[1]\n",
    "    sets = data.shape[0]\n",
    "    mean_derivatives = np.zeros((sets, 1))\n",
    "\n",
    "    for i in range(sets):\n",
    "        x = np.arange(1, n + 1)\n",
    "        x_fake = np.arange(1.1, n, 0.1)\n",
    "        y = data[i, :, 0]\n",
    "\n",
    "        # Linear interpolation of x and y\n",
    "        f = np.interp(x_fake, x, y)\n",
    "\n",
    "        # Calculate the derivatives\n",
    "        df_dx = np.gradient(f, x_fake)\n",
    "\n",
    "        # Calculate the mean derivative for the i-th set\n",
    "        average = np.average(df_dx)\n",
    "        mean_derivatives[i][0] = average\n",
    "\n",
    "    return torch.from_numpy(mean_derivatives)mean_derivatives)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # 3 GRU layers, input_size = features\n",
    "        self.gru_1 = nn.GRU(input_size, 1024, batch_first=True)\n",
    "        self.gru_2 = nn.GRU(1024, 512, batch_first = True)\n",
    "        self.gru_3 = nn.GRU(512, 256, batch_first = True)\n",
    "        # 3 Dense Layers\n",
    "        self.linear_1 = nn.Linear(256, 128)\n",
    "        self.linear_2 = nn.Linear(128, 64)\n",
    "        self.linear_3 = nn.Linear(64, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x,use_cuda=1):\n",
    "        device = torch.device(\"cuda\" if (torch.cuda.is_available() & use_cuda) else \"cpu\")\n",
    "        h0 = torch.zeros(1, x.size(0), 1024).to(device) # initial hidden state for the 1st GRU Layer - (num of layers in the GRU, batch size, num of hidden units in the GRU)\n",
    "        out_gru_1, _ = self.gru_1(x, h0)\n",
    "        out_gru_1 = self.dropout(out_gru_1)\n",
    "\n",
    "        h1 = torch.zeros(1, x.size(0), 512).to(device)\n",
    "        out_gru_2, _ = self.gru_2(out_gru_1, h1)\n",
    "        out_gru_2 = self.dropout(out_gru_2)\n",
    "\n",
    "        h2 = torch.zeros(1, x.size(0), 256).to(device)\n",
    "        out_gru_3, _ = self.gru_3(out_gru_2, h2)\n",
    "        out_gru_3 = self.dropout(out_gru_3)\n",
    "\n",
    "        out_dense_1 = self.linear_1(out_gru_3[:, -1, :])\n",
    "        out_dense_2 = self.linear_2(out_dense_1)\n",
    "        out_dense_3 = self.linear_3(out_dense_2)\n",
    "\n",
    "        return out_dense_3,out_gru_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "asset = \"LTC\"\n",
    "timestamp = \"2021-04-08 13:50:00\"\n",
    "\n",
    "starting_index = 0\n",
    "testing_duration = 22\n",
    "sliding_window_size = 10\n",
    "trend_measure_lenth = 12\n",
    "\n",
    "training_duration = 4032\n",
    "train_offset = 8640*4+4032\n",
    "classification_label_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-06-12T22:35:55.3485878Z",
       "execution_start_time": "2023-06-12T22:35:51.3486468Z",
       "livy_statement_state": "available",
       "parent_msg_id": "d63efab1-eae0-4725-93be-9818af034248",
       "queued_time": "2023-06-12T22:35:51.2212188Z",
       "session_id": "44",
       "session_start_time": null,
       "spark_jobs": null,
       "spark_pool": "predictorspool",
       "state": "finished",
       "statement_id": 102
      },
      "text/plain": [
       "StatementMeta(predictorspool, 44, 102, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if asset == \"BTC\":\n",
    "    df_init = spark.read.load('abfss://predictorfilesystem@predictorgen2storage.dfs.core.windows.net/init_data/btc_init.csv', format='csv').toPandas()\n",
    "    df = spark.read.load('abfss://predictorfilesystem@predictorgen2storage.dfs.core.windows.net/btc_pca.csv', format='csv').toPandas()\n",
    "    wgan_model_url = \"https://predictorgen2storage.dfs.core.windows.net/predictorfilesystem/trained_models/price_prediction_models/generator_1000.pth?sp=r&st=2023-06-12T18:50:45Z&se=2023-06-30T02:50:45Z&spr=https&sv=2022-11-02&sr=c&sig=o%2FckYvYWlKr85l5wbT2akOPnR61a3GohlamU%2BaQUHmU%3D\"\n",
    "    xgb_model_url = \"https://predictorgen2storage.dfs.core.windows.net/predictorfilesystem/trained_models/bottom_point_prediction_models/BPC_BTC.model?sp=r&st=2023-06-12T18:50:45Z&se=2023-06-30T02:50:45Z&spr=https&sv=2022-11-02&sr=c&sig=o%2FckYvYWlKr85l5wbT2akOPnR61a3GohlamU%2BaQUHmU%3D\"\n",
    "\n",
    "elif asset == \"ETH\":\n",
    "    df_init = spark.read.load('abfss://predictorfilesystem@predictorgen2storage.dfs.core.windows.net/init_data/eth_init.csv', format='csv').toPandas()\n",
    "    df = spark.read.load('abfss://predictorfilesystem@predictorgen2storage.dfs.core.windows.net/eth_pca.csv', format='csv').toPandas()\n",
    "    wgan_model_url = \"https://predictorgen2storage.dfs.core.windows.net/predictorfilesystem/trained_models/price_prediction_models/wgan_eth.pth?sp=r&st=2023-06-12T18:50:45Z&se=2023-06-30T02:50:45Z&spr=https&sv=2022-11-02&sr=c&sig=o%2FckYvYWlKr85l5wbT2akOPnR61a3GohlamU%2BaQUHmU%3D\"\n",
    "    xgb_model_url = \"https://predictorgen2storage.dfs.core.windows.net/predictorfilesystem/trained_models/bottom_point_prediction_models/BPC_WGAN_ETH.model?sp=r&st=2023-06-12T18:50:45Z&se=2023-06-30T02:50:45Z&spr=https&sv=2022-11-02&sr=c&sig=o%2FckYvYWlKr85l5wbT2akOPnR61a3GohlamU%2BaQUHmU%3D\"\n",
    "\n",
    "elif asset == \"LTC\":\n",
    "    df_init = spark.read.option(\"header\", \"true\").csv(\"abfss://predictorfilesystem@predictorgen2storage.dfs.core.windows.net/init_data/ltc_init.csv\").toPandas()\n",
    "    df = spark.read.option(\"header\", \"true\").csv('abfss://predictorfilesystem@predictorgen2storage.dfs.core.windows.net/ltc_pca.csv').toPandas()\n",
    "    # df = spark.read.load('abfss://predictorfilesystem@predictorgen2storage.dfs.core.windows.net/ltc_pca.csv', format='csv').toPandas()\n",
    "    wgan_model_url = \"https://predictorgen2storage.dfs.core.windows.net/predictorfilesystem/trained_models/price_prediction_models/wgan_ltc.pth?sp=r&st=2023-06-12T18:50:45Z&se=2023-06-30T02:50:45Z&spr=https&sv=2022-11-02&sr=c&sig=o%2FckYvYWlKr85l5wbT2akOPnR61a3GohlamU%2BaQUHmU%3D\"\n",
    "    xgb_model_url = \"https://predictorgen2storage.dfs.core.windows.net/predictorfilesystem/trained_models/bottom_point_prediction_models/BPC_WGAN_LTC.model?sp=r&st=2023-06-12T18:50:45Z&se=2023-06-30T02:50:45Z&spr=https&sv=2022-11-02&sr=c&sig=o%2FckYvYWlKr85l5wbT2akOPnR61a3GohlamU%2BaQUHmU%3D\"\n",
    "\n",
    "elif asset == \"AAPL\":\n",
    "    df_init = spark.read.load('abfss://predictorfilesystem@predictorgen2storage.dfs.core.windows.net/init_data/AAPL_data_5min.csv', format='csv').toPandas()\n",
    "    df = spark.read.load('abfss://predictorfilesystem@predictorgen2storage.dfs.core.windows.net/aalp_pca.csv', format='csv').toPandas()\n",
    "    wgan_model_url = \"https://predictorgen2storage.dfs.core.windows.net/predictorfilesystem/trained_models/price_prediction_models/wgan_aapl.pth?sp=r&st=2023-06-12T18:50:45Z&se=2023-06-30T02:50:45Z&spr=https&sv=2022-11-02&sr=c&sig=o%2FckYvYWlKr85l5wbT2akOPnR61a3GohlamU%2BaQUHmU%3D\"\n",
    "    xgb_model_url = \"https://predictorgen2storage.dfs.core.windows.net/predictorfilesystem/trained_models/bottom_point_prediction_models/BPC_WGAN_aapl.model?sp=r&st=2023-06-12T18:50:45Z&se=2023-06-30T02:50:45Z&spr=https&sv=2022-11-02&sr=c&sig=o%2FckYvYWlKr85l5wbT2akOPnR61a3GohlamU%2BaQUHmU%3D\"\n",
    "    \n",
    "elif asset == \"TSLA\":\n",
    "    df_init = spark.read.load('abfss://predictorfilesystem@predictorgen2storage.dfs.core.windows.net/init_data/TSLA_data_5min.csv', format='csv').toPandas()\n",
    "    df = spark.read.load('abfss://predictorfilesystem@predictorgen2storage.dfs.core.windows.net/tsla_pca.csv', format='csv').toPandas()\n",
    "    wgan_model_url = \"https://predictorgen2storage.dfs.core.windows.net/predictorfilesystem/trained_models/price_prediction_models/wgan_tslr_3.pth?sp=r&st=2023-06-12T18:50:45Z&se=2023-06-30T02:50:45Z&spr=https&sv=2022-11-02&sr=c&sig=o%2FckYvYWlKr85l5wbT2akOPnR61a3GohlamU%2BaQUHmU%3D\"\n",
    "    xgb_model_url = \"https://predictorgen2storage.dfs.core.windows.net/predictorfilesystem/trained_models/bottom_point_prediction_models/BPC_WGAN_TSLA.model?sp=r&st=2023-06-12T18:50:45Z&se=2023-06-30T02:50:45Z&spr=https&sv=2022-11-02&sr=c&sig=o%2FckYvYWlKr85l5wbT2akOPnR61a3GohlamU%2BaQUHmU%3D\"\n",
    "    \n",
    "elif asset == \"SBUX\":\n",
    "    df_init = spark.read.load('abfss://predictorfilesystem@predictorgen2storage.dfs.core.windows.net/init_data/SBUX_data_5min_2.csv', format='csv').toPandas()\n",
    "    df = spark.read.load('abfss://predictorfilesystem@predictorgen2storage.dfs.core.windows.net/sbux_pca.csv', format='csv').toPandas()\n",
    "    wgan_model_url = \"https://predictorgen2storage.dfs.core.windows.net/predictorfilesystem/trained_models/price_prediction_models/wgan_sbux.pth?sp=r&st=2023-06-12T18:50:45Z&se=2023-06-30T02:50:45Z&spr=https&sv=2022-11-02&sr=c&sig=o%2FckYvYWlKr85l5wbT2akOPnR61a3GohlamU%2BaQUHmU%3D\"\n",
    "    xgb_model_url = \"https://predictorgen2storage.dfs.core.windows.net/predictorfilesystem/trained_models/bottom_point_prediction_models/BPC_WGAN_SBUX.model?sp=r&st=2023-06-12T18:50:45Z&se=2023-06-30T02:50:45Z&spr=https&sv=2022-11-02&sr=c&sig=o%2FckYvYWlKr85l5wbT2akOPnR61a3GohlamU%2BaQUHmU%3D\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-06-12T22:35:55.6947666Z",
       "execution_start_time": "2023-06-12T22:35:55.4858595Z",
       "livy_statement_state": "available",
       "parent_msg_id": "62fded4c-3a7a-4612-9de4-a10f005f9e6b",
       "queued_time": "2023-06-12T22:35:52.2447267Z",
       "session_id": "44",
       "session_start_time": null,
       "spark_jobs": null,
       "spark_pool": "predictorspool",
       "state": "finished",
       "statement_id": 103
      },
      "text/plain": [
       "StatementMeta(predictorspool, 44, 103, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['_c0', 'Open_time', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
       "       'Close_time', 'Quote_asset_volume', 'Number_of_trades',\n",
       "       'Taker_buy_base_asset_volume', 'Taker_buy_quote_asset_volume',\n",
       "       'Unknown', 'Datetime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-06-12T22:35:55.9940606Z",
       "execution_start_time": "2023-06-12T22:35:55.837946Z",
       "livy_statement_state": "available",
       "parent_msg_id": "42e3ddac-a364-4ba9-b448-a4d8370c8990",
       "queued_time": "2023-06-12T22:35:54.424812Z",
       "session_id": "44",
       "session_start_time": null,
       "spark_jobs": null,
       "spark_pool": "predictorspool",
       "state": "finished",
       "statement_id": 104
      },
      "text/plain": [
       "StatementMeta(predictorspool, 44, 104, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelG = torch.hub.load_state_dict_from_url(wgan_model_url, map_location=torch.device('cpu'))\n",
    "state_dict = modelG.state_dict()\n",
    "modelG = Generator(df.shape[1]-1)\n",
    "modelG.load_state_dict(state_dict)\n",
    "modelG.eval()\n",
    "\n",
    "local_model_path, _ = urllib.request.urlretrieve(xgb_model_url)\n",
    "modelXGB = xgb.XGBClassifier()\n",
    "modelXGB.load_model(local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-06-12T22:35:56.287357Z",
       "execution_start_time": "2023-06-12T22:35:56.1332339Z",
       "livy_statement_state": "available",
       "parent_msg_id": "cb78656e-7a7a-4096-aca1-e9338c7b9933",
       "queued_time": "2023-06-12T22:35:55.45742Z",
       "session_id": "44",
       "session_start_time": null,
       "spark_jobs": null,
       "spark_pool": "predictorspool",
       "state": "finished",
       "statement_id": 105
      },
      "text/plain": [
       "StatementMeta(predictorspool, 44, 105, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = df_init[df_init['Datetime'] == timestamp].index.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-06-12T22:35:58.0097753Z",
       "execution_start_time": "2023-06-12T22:35:57.8478889Z",
       "livy_statement_state": "available",
       "parent_msg_id": "a34bba70-d89a-4c2f-ab43-28d779b6cf4e",
       "queued_time": "2023-06-12T22:35:57.735482Z",
       "session_id": "44",
       "session_start_time": null,
       "spark_jobs": null,
       "spark_pool": "predictorspool",
       "state": "finished",
       "statement_id": 106
      },
      "text/plain": [
       "StatementMeta(predictorspool, 44, 106, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['pca1', 'pca2', 'pca3', 'pca4', 'pca5', 'pca6', 'pca7', 'pca8', 'pca11',\n",
       "       'pca13', 'pca14', 'pca16', 'pca17', 'pca18', 'pca19', 'pca20', 'pca21',\n",
       "       'Close'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-06-12T22:35:59.3351468Z",
       "execution_start_time": "2023-06-12T22:35:59.1776683Z",
       "livy_statement_state": "available",
       "parent_msg_id": "7e6b0100-572f-49ba-b7dd-4b2241a2e1cf",
       "queued_time": "2023-06-12T22:35:59.0451857Z",
       "session_id": "44",
       "session_start_time": null,
       "spark_jobs": null,
       "spark_pool": "predictorspool",
       "state": "finished",
       "statement_id": 107
      },
      "text/plain": [
       "StatementMeta(predictorspool, 44, 107, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_df = df[\"Close\"]\n",
    "features_df = df.drop(columns=[\"Close\"])\n",
    "\n",
    "train_x = features_df.iloc[train_offset:train_offset+training_duration]\n",
    "train_y = labels_df.iloc[train_offset:train_offset+training_duration]\n",
    "\n",
    "test_x = features_df.iloc[index-testing_duration:index]\n",
    "test_y = labels_df.iloc[index-testing_duration:index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-06-12T22:36:01.1288343Z",
       "execution_start_time": "2023-06-12T22:36:00.9628887Z",
       "livy_statement_state": "available",
       "parent_msg_id": "0bf8432e-673e-4626-ada3-cdedca6f916e",
       "queued_time": "2023-06-12T22:36:00.8448799Z",
       "session_id": "44",
       "session_start_time": null,
       "spark_jobs": null,
       "spark_pool": "predictorspool",
       "state": "finished",
       "statement_id": 108
      },
      "text/plain": [
       "StatementMeta(predictorspool, 44, 108, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "y_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "trend_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "train_x = x_scaler.fit_transform(train_x)\n",
    "test_x = x_scaler.transform(test_x)\n",
    "\n",
    "raw_train_y = train_y.values.reshape(-1, 1)\n",
    "raw_test_y = test_y.values.reshape(-1, 1)\n",
    "train_y = y_scaler.fit_transform(train_y.values.reshape(-1, 1))\n",
    "test_y = y_scaler.transform(test_y.values.reshape(-1, 1))\n",
    "\n",
    "print(type(raw_train_y))\n",
    "print(type(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-06-12T22:36:09.7135275Z",
       "execution_start_time": "2023-06-12T22:36:02.8402961Z",
       "livy_statement_state": "available",
       "parent_msg_id": "4e622162-d47d-4822-8d31-2b5ea3be21ca",
       "queued_time": "2023-06-12T22:36:02.7217585Z",
       "session_id": "44",
       "session_start_time": null,
       "spark_jobs": null,
       "spark_pool": "predictorspool",
       "state": "finished",
       "statement_id": 109
      },
      "text/plain": [
       "StatementMeta(predictorspool, 44, 109, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10, 17])\n"
     ]
    }
   ],
   "source": [
    "# For price prediction model\n",
    "train_x_slide, train_y_slide, train_y_gan,train_y_gan_cl,train_direction_slide = sliding_window(train_x, train_y,raw_train_y, sliding_window_size,classification_label_size,trend_measure_lenth)                \n",
    "test_x_slide, test_y_slide, test_y_gan,test_y_gan_cl,test_direction_slide = sliding_window(test_x, test_y, raw_test_y ,sliding_window_size,classification_label_size,trend_measure_lentpe)\n",
    "\n",
    "train_trend_features = trend_detection(train_direction_slide)\n",
    "test_trend_features = trend_detection(test_direction_slide)\n",
    "train_trend_features = torch.tensor(trend_scaler.fit_transform(train_trend_features))\n",
    "test_trend_features = torch.tensor(trend_scaler.transform(test_trend_features))\n",
    "new_feature_tensor_train = train_trend_features.repeat(1,10)\n",
    "new_feature_tensor_train = new_feature_tensor_train.unsqueeze(2)\n",
    "new_feature_tensor_test = test_trend_features.repeat(1,10)\n",
    "new_feature_tensor_test = new_feature_tensor_test.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-06-12T22:36:10.0190979Z",
       "execution_start_time": "2023-06-12T22:36:09.8505211Z",
       "livy_statement_state": "available",
       "parent_msg_id": "69a43ecd-9b22-4752-ad5c-0f24eea70196",
       "queued_time": "2023-06-12T22:36:06.8860317Z",
       "session_id": "44",
       "session_start_time": null,
       "spark_jobs": null,
       "spark_pool": "predictorspool",
       "state": "finished",
       "statement_id": 110
      },
      "text/plain": [
       "StatementMeta(predictorspool, 44, 110, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def xgboost_test(x,xgmodel):\n",
    "    out_gru_3_xg = x.reshape(x.shape[0], -1)\n",
    "    pred = xgmodel.predict(out_gru_3_xg.detach().cpu().numpy())\n",
    "    pred = torch.tensor(pred).reshape(pred.shape[0],1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-06-12T22:36:25.697851Z",
       "execution_start_time": "2023-06-12T22:36:24.5677223Z",
       "livy_statement_state": "available",
       "parent_msg_id": "d98a1bd9-0ee3-42e4-ac4a-dc768c73dbbf",
       "queued_time": "2023-06-12T22:36:24.4247703Z",
       "session_id": "44",
       "session_start_time": null,
       "spark_jobs": null,
       "spark_pool": "predictorspool",
       "state": "finished",
       "statement_id": 111
      },
      "text/plain": [
       "StatementMeta(predictorspool, 44, 111, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "[[245.01878]\n",
      " [245.09026]\n",
      " [245.04808]\n",
      " [245.20142]\n",
      " [245.20241]\n",
      " [245.16296]\n",
      " [245.04936]\n",
      " [244.85371]\n",
      " [244.62418]\n",
      " [244.43718]]\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "price_prediction,test_input_features = modelG(test_x_slide.to(device))\n",
    "test_input_features = torch.cat((test_input_features, new_feature_tensor_test), dim=2)\n",
    "pred_direction_test = xgboost_test(test_input_features,modelXGB)\n",
    "\n",
    "y_test_true = y_scaler.inverse_transform(price_prediction.detach().numpy())\n",
    "\n",
    "print(pred_direction_test)\n",
    "print(y_test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import grad as torch_grad\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.misc import derivative\n",
    "\n",
    "def sliding_window(x, y, y_raw ,feature_window,label_window,trend_window):\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "    y_gan_pr = []\n",
    "    y_gan_cl = []\n",
    "    y_gan_tr = []\n",
    "    backward_length = max(trend_window,label_window)\n",
    "    for i in range(backward_length, x.shape[0]-label_window):\n",
    "        tmp_x = x[i - feature_window: i, :]\n",
    "        tmp_y = y[i]\n",
    "        tmp_y_gan_pr = y[i - feature_window: i + 1]\n",
    "        tmp_y_gan_cl = y_raw[i - label_window: i + label_window+1]\n",
    "        tmp_y_gan_tr = y_raw[i - trend_window: i, :]\n",
    "        x_.append(tmp_x)\n",
    "        y_.append(tmp_y)\n",
    "        y_gan_pr.append(tmp_y_gan_pr)\n",
    "        y_gan_cl.append(tmp_y_gan_cl)\n",
    "        y_gan_tr.append(tmp_y_gan_tr)\n",
    "    x_ = torch.from_numpy(np.array(x_)).float()\n",
    "    y_ = torch.from_numpy(np.array(y_)).float()\n",
    "    # print(y_gan_cl.shape)\n",
    "    # print(type(y_gan_cl))\n",
    "    y_gan_pr = torch.from_numpy(np.array(y_gan_pr)).float()\n",
    "    y_gan_cl = np.array(y_gan_cl)\n",
    "    y_gan_cl = y_gan_cl.astype(np.float64)\n",
    "    y_gan_cl = torch.from_numpy(np.array(y_gan_cl)).float()\n",
    "    y_gan_tr = np.array(y_gan_tr)\n",
    "    y_gan_tr = y_gan_tr.astype(np.float64)\n",
    "    y_gan_tr = torch.from_numpy(np.array(y_gan_tr)).float()\n",
    "    return x_, y_, y_gan_pr,y_gan_cl,y_gan_tr\n",
    "\n",
    "def trend_detection(data):\n",
    "    n = data.shape[1]\n",
    "    sets = data.shape[0]\n",
    "    mean_derivatives = np.zeros((sets, 1))\n",
    "\n",
    "    for i in range(sets):\n",
    "        x = np.arange(1, n + 1)\n",
    "        x_fake = np.arange(1.1, n, 0.1)\n",
    "        y = data[i, :, 0]\n",
    "\n",
    "        # Linear interpolation of x and y\n",
    "        f = np.interp(x_fake, x, y)\n",
    "\n",
    "        # Calculate the derivatives\n",
    "        df_dx = np.gradient(f, x_fake)\n",
    "\n",
    "        # Calculate the mean derivative for the i-th set\n",
    "        average = np.average(df_dx)\n",
    "        mean_derivatives[i][0] = average\n",
    "\n",
    "    return torch.from_numpy(mean_derivatives)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # 3 GRU layers, input_size = features\n",
    "        self.gru_1 = nn.GRU(input_size, 1024, batch_first=True)\n",
    "        self.gru_2 = nn.GRU(1024, 512, batch_first = True)\n",
    "        self.gru_3 = nn.GRU(512, 256, batch_first = True)\n",
    "        # 3 Dense Layers\n",
    "        self.linear_1 = nn.Linear(256, 128)\n",
    "        self.linear_2 = nn.Linear(128, 64)\n",
    "        self.linear_3 = nn.Linear(64, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x,use_cuda=1):\n",
    "        device = torch.device(\"cuda\" if (torch.cuda.is_available() & use_cuda) else \"cpu\")\n",
    "        h0 = torch.zeros(1, x.size(0), 1024).to(device) # initial hidden state for the 1st GRU Layer - (num of layers in the GRU, batch size, num of hidden units in the GRU)\n",
    "        out_gru_1, _ = self.gru_1(x, h0)\n",
    "        out_gru_1 = self.dropout(out_gru_1)\n",
    "\n",
    "        h1 = torch.zeros(1, x.size(0), 512).to(device)\n",
    "        out_gru_2, _ = self.gru_2(out_gru_1, h1)\n",
    "        out_gru_2 = self.dropout(out_gru_2)\n",
    "\n",
    "        h2 = torch.zeros(1, x.size(0), 256).to(device)\n",
    "        out_gru_3, _ = self.gru_3(out_gru_2, h2)\n",
    "        out_gru_3 = self.dropout(out_gru_3)\n",
    "\n",
    "        out_dense_1 = self.linear_1(out_gru_3[:, -1, :])\n",
    "        out_dense_2 = self.linear_2(out_dense_1)\n",
    "        out_dense_3 = self.linear_3(out_dense_2)\n",
    "\n",
    "        return out_dense_3,out_gru_3\n",
    "    \n",
    "def xgboost_test(x,xgmodel):\n",
    "    out_gru_3_xg = x.reshape(x.shape[0], -1)\n",
    "    pred = xgmodel.predict(out_gru_3_xg.detach().cpu().numpy())\n",
    "    pred = torch.tensor(pred).reshape(pred.shape[0],1)\n",
    "    return pred    \n",
    "\n",
    "#Constants    \n",
    "starting_index = 0\n",
    "testing_duration = 22\n",
    "sliding_window_size = 10\n",
    "trend_measure_lenth = 12\n",
    "training_duration = 4032\n",
    "train_offset = 8640*4+4032\n",
    "classification_label_size = 0\n",
    "device = 'cpu'\n",
    "\n",
    "def get_prediction(timestamp, asset):\n",
    "    \n",
    "    if asset == \"BTC\":\n",
    "        df_init = pd.read_csv(\"/kaggle/input/df-pca-n/df_pca_n.csv\")\n",
    "        df = pd.read_csv(\"/kaggle/input/df-pca-n/df_pca_n.csv\")\n",
    "        wgan_model_url = \"wgan_model\"\n",
    "        xgb_model_url = \"xgboost_model\"\n",
    "        \n",
    "    elif asset == \"ETH\":\n",
    "        df_init = pd.read_csv(\"/kaggle/input/df-pca-n/df_pca_n.csv\")\n",
    "        df = pd.read_csv(\"/kaggle/input/df-pca-n/df_pca_n.csv\")\n",
    "        wgan_model_url = \"wgan_model\"\n",
    "        xgb_model_url = \"xgboost_model\"\n",
    "        \n",
    "    elif asset == \"LTC\":\n",
    "        df_init = pd.read_csv(\"/kaggle/input/df-pca-n/df_pca_n.csv\")\n",
    "        df = pd.read_csv(\"/kaggle/input/df-pca-n/df_pca_n.csv\")\n",
    "        wgan_model_url = \"wgan_model\"\n",
    "        xgb_model_url = \"xgboost_model\"\n",
    "        \n",
    "    elif asset == \"AAPL\":\n",
    "        df_init = pd.read_csv(\"/kaggle/input/df-pca-n/df_pca_n.csv\")\n",
    "        df = pd.read_csv(\"/kaggle/input/df-pca-n/df_pca_n.csv\")\n",
    "        wgan_model_url = \"wgan_model\"\n",
    "        xgb_model_url = \"xgboost_model\"\n",
    "        \n",
    "    elif asset == \"TSLA\":\n",
    "        df_init = pd.read_csv(\"/kaggle/input/df-pca-n/df_pca_n.csv\")\n",
    "        df = pd.read_csv(\"/kaggle/input/df-pca-n/df_pca_n.csv\")\n",
    "        wgan_model_url = \"wgan_model\"\n",
    "        xgb_model_url = \"xgboost_model\"\n",
    "        \n",
    "    elif asset == \"SBUX\":\n",
    "        df_init = pd.read_csv(\"/kaggle/input/df-pca-n/df_pca_n.csv\")\n",
    "        df = pd.read_csv(\"/kaggle/input/df-pca-n/df_pca_n.csv\")\n",
    "        wgan_model_url = \"wgan_model\"\n",
    "        xgb_model_url = \"xgboost_model\"\n",
    "    \n",
    "    # Index of the required timestep\n",
    "    index = df_init[df_init['Datetime'] == timestamp].index.item()\n",
    "    \n",
    "    # Train test split\n",
    "    labels_df = df[\"Close\"]\n",
    "    features_df = df.drop(columns=[\"Close\"])\n",
    "    train_x = features_df.iloc[train_offset:train_offset+training_duration]\n",
    "    train_y = labels_df.iloc[train_offset:train_offset+training_duration]\n",
    "    test_x = features_df.iloc[index-testing_duration:index]\n",
    "    test_y = labels_df.iloc[index-testing_duration:index]\n",
    "    \n",
    "    # Scaling the Dataset \n",
    "    x_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    y_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    trend_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    train_x = x_scaler.fit_transform(train_x)\n",
    "    test_x = x_scaler.transform(test_x)\n",
    "    raw_train_y = train_y.values.reshape(-1, 1)\n",
    "    raw_test_y = test_y.values.reshape(-1, 1)\n",
    "    train_y = y_scaler.fit_transform(train_y.values.reshape(-1, 1))\n",
    "    test_y = y_scaler.transform(test_y.values.reshape(-1, 1))\n",
    "    \n",
    "    # Input data preprocess\n",
    "    train_x_slide, train_y_slide, train_y_gan,train_y_gan_cl,train_direction_slide = sliding_window(train_x, train_y,raw_train_y, sliding_window_size,classification_label_size,trend_measure_lenth)                \n",
    "    test_x_slide, test_y_slide, test_y_gan,test_y_gan_cl,test_direction_slide = sliding_window(test_x, test_y, raw_test_y ,sliding_window_size,classification_label_size,trend_measure_lenth)\n",
    "    train_trend_features = trend_detection(train_direction_slide)\n",
    "    test_trend_features = trend_detection(test_direction_slide)\n",
    "    train_trend_features = torch.tensor(trend_scaler.fit_transform(train_trend_features))\n",
    "    test_trend_features = torch.tensor(trend_scaler.transform(test_trend_features))\n",
    "    new_feature_tensor_train = train_trend_features.repeat(1,10)\n",
    "    new_feature_tensor_train = new_feature_tensor_train.unsqueeze(2)\n",
    "    new_feature_tensor_test = test_trend_features.repeat(1,10)\n",
    "    new_feature_tensor_test = new_feature_tensor_test.unsqueeze(2)\n",
    "    \n",
    "    modelG1 = torch.load(wgan_model_url, map_location=torch.device('cpu'))\n",
    "    state_dict = modelG1.state_dict()\n",
    "    modelG2 = Generator(train_x.shape[1])\n",
    "    modelG2.load_state_dict(state_dict)\n",
    "    modelG2.eval()\n",
    "    \n",
    "    model_xgboost = xgb.XGBClassifier()\n",
    "    model_xgboost.load_model(xgb_model_url)\n",
    "    \n",
    "    price_prediction,test_input_features = modelG2(test_x_slide.to(device))\n",
    "    test_input_features = torch.cat((test_input_features, new_feature_tensor_test), dim=2)\n",
    "    pred_direction_test = xgboost_test(test_input_features,model_xgboost)\n",
    "\n",
    "    y_test_true = y_scaler.inverse_transform(price_prediction.detach().numpy())\n",
    "\n",
    "    print(pred_direction_test)\n",
    "    print(y_test_true)\n"
   ]
  }
 ],
 "metadata": {
  "description": null,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "save_output": true,
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
