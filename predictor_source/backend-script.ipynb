{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import grad as torch_grad\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.misc import derivative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "train_x, train_y,raw_train_y, sliding_window_size,classification_label_size,trend_measure_lenth\n",
    "\n",
    "def sliding_window(x, y, y_raw ,feature_window,label_window,trend_window):\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "    y_gan_pr = []\n",
    "    y_gan_cl = []\n",
    "    y_gan_tr = []\n",
    "    backward_length = max(trend_window,label_window)\n",
    "    for i in range(backward_length, x.shape[0]-label_window):\n",
    "        tmp_x = x[i - feature_window: i, :]\n",
    "        tmp_y = y[i]\n",
    "        tmp_y_gan_pr = y[i - feature_window: i + 1]\n",
    "        tmp_y_gan_cl = y_raw[i - label_window: i + label_window+1]\n",
    "        tmp_y_gan_tr = y_raw[i - trend_window: i, :]\n",
    "        x_.append(tmp_x)\n",
    "        y_.append(tmp_y)\n",
    "        y_gan_pr.append(tmp_y_gan_pr)\n",
    "        y_gan_cl.append(tmp_y_gan_cl)\n",
    "        y_gan_tr.append(tmp_y_gan_tr)\n",
    "    x_ = torch.from_numpy(np.array(x_)).float()\n",
    "    y_ = torch.from_numpy(np.array(y_)).float()\n",
    "    # print(y_gan_cl.shape)\n",
    "    # print(type(y_gan_cl))\n",
    "    y_gan_pr = torch.from_numpy(np.array(y_gan_pr)).float()\n",
    "    y_gan_cl = np.array(y_gan_cl)\n",
    "    y_gan_cl = y_gan_cl.astype(np.float64)\n",
    "    y_gan_cl = torch.from_numpy(np.array(y_gan_cl)).float()\n",
    "    y_gan_tr = np.array(y_gan_tr)\n",
    "    y_gan_tr = y_gan_tr.astype(np.float64)\n",
    "    y_gan_tr = torch.from_numpy(np.array(y_gan_tr)).float()\n",
    "    return x_, y_, y_gan_pr,y_gan_cl,y_gan_tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# def trend_detection(data):\n",
    "#     n = data.shape[1]\n",
    "#     sets = data.shape[0]\n",
    "#     mean_derivatives = np.zeros((sets,1))\n",
    "    \n",
    "#     data = data.numpy()\n",
    "\n",
    "#     for i in range(sets):\n",
    "#         # Select the i-th 20 set\n",
    "#         x = np.arange(1,n+1)\n",
    "#         x_fake = np.arange(1.1, n, 0.1)\n",
    "#         y = data[i, :, 0]\n",
    "#         # Simple interpolation of x and y    \n",
    "#         f = interp1d(x, y)\n",
    "        \n",
    "#         # derivative of y with respect to x\n",
    "#         df_dx = nd.Derivative(f, step=1e-6)(x_fake)\n",
    "#         # Calculate the mean derivative for the i-th 20 set\n",
    "#         average = np.average(df_dx)\n",
    "#         mean_derivatives[i][0] = average\n",
    "#     return  torch.from_num\n",
    "\n",
    "def trend_detection(data):\n",
    "    n = data.shape[1]\n",
    "    sets = data.shape[0]\n",
    "    mean_derivatives = np.zeros((sets, 1))\n",
    "\n",
    "    for i in range(sets):\n",
    "        x = np.arange(1, n + 1)\n",
    "        x_fake = np.arange(1.1, n, 0.1)\n",
    "        y = data[i, :, 0]\n",
    "\n",
    "        # Linear interpolation of x and y\n",
    "        f = np.interp(x_fake, x, y)\n",
    "\n",
    "        # Calculate the derivatives\n",
    "        df_dx = np.gradient(f, x_fake)\n",
    "\n",
    "        # Calculate the mean derivative for the i-th set\n",
    "        average = np.average(df_dx)\n",
    "        mean_derivatives[i][0] = average\n",
    "\n",
    "    return torch.from_numpy(mean_derivatives)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # 3 GRU layers, input_size = features\n",
    "        self.gru_1 = nn.GRU(input_size, 1024, batch_first=True)\n",
    "        self.gru_2 = nn.GRU(1024, 512, batch_first = True)\n",
    "        self.gru_3 = nn.GRU(512, 256, batch_first = True)\n",
    "        # 3 Dense Layers\n",
    "        self.linear_1 = nn.Linear(256, 128)\n",
    "        self.linear_2 = nn.Linear(128, 64)\n",
    "        self.linear_3 = nn.Linear(64, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x,use_cuda=0):\n",
    "        h0 = torch.zeros(1, x.size(0), 1024) # initial hidden state for the 1st GRU Layer - (num of layers in the GRU, batch size, num of hidden units in the GRU)\n",
    "        out_gru_1, _ = self.gru_1(x, h0)\n",
    "        out_gru_1 = self.dropout(out_gru_1)\n",
    "\n",
    "        h1 = torch.zeros(1, x.size(0), 512)\n",
    "        out_gru_2, _ = self.gru_2(out_gru_1, h1)\n",
    "        out_gru_2 = self.dropout(out_gru_2)\n",
    "\n",
    "        h2 = torch.zeros(1, x.size(0), 256)\n",
    "        out_gru_3, _ = self.gru_3(out_gru_2, h2)\n",
    "        out_gru_3 = self.dropout(out_gru_3)\n",
    "\n",
    "        out_dense_1 = self.linear_1(out_gru_3[:, -1, :])\n",
    "        out_dense_2 = self.linear_2(out_dense_1)\n",
    "        out_dense_3 = self.linear_3(out_dense_2)\n",
    "\n",
    "        return out_dense_3,out_gru_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "asset = \"BTC\"\n",
    "timestamp = \"2021-04-08 13:50:00\"\n",
    "\n",
    "starting_index = 0\n",
    "testing_duration = 22\n",
    "sliding_window_size = 10\n",
    "trend_measure_lenth = 12\n",
    "\n",
    "training_duration = 4032\n",
    "train_offset = 8640*4+4032\n",
    "classification_label_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "if asset == \"BTC\":\n",
    "    df_init = pd.read_csv(\"dataset/initial/btc_init.csv\")\n",
    "    df = pd.read_csv(\"dataset/preprocessed/btc_pca.csv\")\n",
    "    wgan_model_url = \"trained_models/wgan/wgan_btc.pth\"\n",
    "    xgb_model_url = \"trained_models/bottom/BPC_WGAN_BTC.model\"\n",
    "\n",
    "elif asset == \"ETH\":\n",
    "    df_init = pd.read_csv(\"dataset/initial/eth_init.csv\")\n",
    "    df = pd.read_csv(\"dataset/preprocessed/eth_pca.csv\")\n",
    "    wgan_model_url = \"trained_models/wgan/wgan_eth.pth\"\n",
    "    xgb_model_url = \"trained_models/bottom/BPC_WGAN_ETH.model\"\n",
    "\n",
    "elif asset == \"LTC\":\n",
    "    df_init = pd.read_csv(\"dataset/initial/ltc_init.csv\")\n",
    "    df = pd.read_csv(\"dataset/preprocessed/ltc_pca.csv\")\n",
    "    wgan_model_url = \"trained_models/wgan/wgan_ltc.pth\"\n",
    "    xgb_model_url = \"trained_models/bottom/BPC_WGAN_LTC.model\"\n",
    "\n",
    "elif asset == \"AAPL\":\n",
    "    df_init = pd.read_csv(\"dataset/initial/aapl_init.csv\")\n",
    "    df = pd.read_csv(\"dataset/preprocessed/aapl_pca.csv\")\n",
    "    wgan_model_url = \"trained_models/wgan/wgan_aapl.pth\"\n",
    "    xgb_model_url = \"trained_models/bottom/BPC_WGAN_AAPL.model\"\n",
    "\n",
    "elif asset == \"TSLA\":\n",
    "    df_init = pd.read_csv(\"dataset/initial/tsla_init.csv\")\n",
    "    df = pd.read_csv(\"dataset/preprocessed/tsla_pca.csv\")\n",
    "    wgan_model_url = \"trained_models/wgan/wgan_tsla.pth\"\n",
    "    xgb_model_url = \"trained_models/bottom/BPC_WGAN_TSLA.model\"\n",
    "\n",
    "elif asset == \"SBUX\":\n",
    "    df_init = pd.read_csv(\"dataset/initial/sbux_init.csv\")\n",
    "    df = pd.read_csv(\"dataset/preprocessed/sbux_pca.csv\")\n",
    "    wgan_model_url = \"trained_models/wgan/wgan_sbux.pth\"\n",
    "    xgb_model_url = \"trained_models/bottom/BPC_WGAN_SBUX.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Open_time', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
       "       'Close_time', 'Quote_asset_volume', 'Number_of_trades',\n",
       "       'Taker_buy_base_asset_volume', 'Taker_buy_quote_asset_volume',\n",
       "       'Unknown', 'Datetime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "index = df_init[df_init['Datetime'] == timestamp].index.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                    45670\n",
       "Open_time                           1618010000000.0\n",
       "Open                                       58154.87\n",
       "High                                       58184.58\n",
       "Low                                        58108.29\n",
       "Close                                      58184.58\n",
       "Volume                                   133.935882\n",
       "Close_time                          1618010000000.0\n",
       "Quote_asset_volume                      7787300.851\n",
       "Number_of_trades                               4286\n",
       "Taker_buy_base_asset_volume               68.109609\n",
       "Taker_buy_quote_asset_volume              3960026.5\n",
       "Unknown                                           0\n",
       "Datetime                        2021-04-08 13:50:00\n",
       "Name: 45670, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df_init.iloc[index:index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "labels_df = df[\"Close\"]\n",
    "features_df = df.drop(columns=[\"Close\"])\n",
    "\n",
    "train_x = features_df.iloc[train_offset:train_offset+training_duration]\n",
    "train_y = labels_df.iloc[train_offset:train_offset+training_duration]\n",
    "\n",
    "test_x = features_df.iloc[index-testing_duration:index+1]\n",
    "test_y = labels_df.iloc[index-testing_duration:index+1]\n",
    "real_y = df_init.iloc[index-10:index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Open_time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close_time</th>\n",
       "      <th>Quote_asset_volume</th>\n",
       "      <th>Number_of_trades</th>\n",
       "      <th>Taker_buy_base_asset_volume</th>\n",
       "      <th>Taker_buy_quote_asset_volume</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45660</th>\n",
       "      <td>45660</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>58430.16</td>\n",
       "      <td>58430.17</td>\n",
       "      <td>58368.04</td>\n",
       "      <td>58376.27</td>\n",
       "      <td>59.445929</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>3471320.319</td>\n",
       "      <td>3260</td>\n",
       "      <td>27.469728</td>\n",
       "      <td>1604075.748</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-08 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45661</th>\n",
       "      <td>45661</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>58376.28</td>\n",
       "      <td>58385.42</td>\n",
       "      <td>58321.74</td>\n",
       "      <td>58361.24</td>\n",
       "      <td>97.938052</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>5714994.843</td>\n",
       "      <td>3765</td>\n",
       "      <td>49.064842</td>\n",
       "      <td>2863136.553</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-08 13:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45662</th>\n",
       "      <td>45662</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>58361.24</td>\n",
       "      <td>58361.24</td>\n",
       "      <td>58201.30</td>\n",
       "      <td>58264.10</td>\n",
       "      <td>138.791563</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>8087487.627</td>\n",
       "      <td>5370</td>\n",
       "      <td>66.534853</td>\n",
       "      <td>3876654.192</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-08 13:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45663</th>\n",
       "      <td>45663</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>58264.10</td>\n",
       "      <td>58294.88</td>\n",
       "      <td>58211.00</td>\n",
       "      <td>58232.12</td>\n",
       "      <td>83.108323</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>4841081.447</td>\n",
       "      <td>3493</td>\n",
       "      <td>50.694005</td>\n",
       "      <td>2952965.767</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-08 13:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45664</th>\n",
       "      <td>45664</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>58232.13</td>\n",
       "      <td>58272.15</td>\n",
       "      <td>58229.30</td>\n",
       "      <td>58260.49</td>\n",
       "      <td>84.873621</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>4943439.721</td>\n",
       "      <td>3312</td>\n",
       "      <td>52.779177</td>\n",
       "      <td>3074098.136</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-08 13:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45665</th>\n",
       "      <td>45665</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>58260.48</td>\n",
       "      <td>58262.80</td>\n",
       "      <td>58105.22</td>\n",
       "      <td>58178.00</td>\n",
       "      <td>131.702736</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>7660996.206</td>\n",
       "      <td>5248</td>\n",
       "      <td>47.561720</td>\n",
       "      <td>2766511.388</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-08 13:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45666</th>\n",
       "      <td>45666</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>58178.00</td>\n",
       "      <td>58225.93</td>\n",
       "      <td>58128.21</td>\n",
       "      <td>58200.01</td>\n",
       "      <td>104.519037</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>6081276.242</td>\n",
       "      <td>4277</td>\n",
       "      <td>57.195113</td>\n",
       "      <td>3328089.105</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-08 13:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45667</th>\n",
       "      <td>45667</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>58200.00</td>\n",
       "      <td>58229.06</td>\n",
       "      <td>58149.24</td>\n",
       "      <td>58190.72</td>\n",
       "      <td>100.349232</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>5839902.629</td>\n",
       "      <td>3925</td>\n",
       "      <td>58.730951</td>\n",
       "      <td>3417842.734</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-08 13:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45668</th>\n",
       "      <td>45668</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>58190.72</td>\n",
       "      <td>58278.53</td>\n",
       "      <td>58190.72</td>\n",
       "      <td>58201.78</td>\n",
       "      <td>70.695408</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>4117410.120</td>\n",
       "      <td>3204</td>\n",
       "      <td>40.784166</td>\n",
       "      <td>2375271.787</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-08 13:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45669</th>\n",
       "      <td>45669</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>58201.78</td>\n",
       "      <td>58245.09</td>\n",
       "      <td>58145.36</td>\n",
       "      <td>58154.87</td>\n",
       "      <td>99.175260</td>\n",
       "      <td>1.618010e+12</td>\n",
       "      <td>5771749.838</td>\n",
       "      <td>3815</td>\n",
       "      <td>48.699615</td>\n",
       "      <td>2834077.657</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-08 13:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     Open_time      Open      High       Low     Close  \\\n",
       "45660       45660  1.618010e+12  58430.16  58430.17  58368.04  58376.27   \n",
       "45661       45661  1.618010e+12  58376.28  58385.42  58321.74  58361.24   \n",
       "45662       45662  1.618010e+12  58361.24  58361.24  58201.30  58264.10   \n",
       "45663       45663  1.618010e+12  58264.10  58294.88  58211.00  58232.12   \n",
       "45664       45664  1.618010e+12  58232.13  58272.15  58229.30  58260.49   \n",
       "45665       45665  1.618010e+12  58260.48  58262.80  58105.22  58178.00   \n",
       "45666       45666  1.618010e+12  58178.00  58225.93  58128.21  58200.01   \n",
       "45667       45667  1.618010e+12  58200.00  58229.06  58149.24  58190.72   \n",
       "45668       45668  1.618010e+12  58190.72  58278.53  58190.72  58201.78   \n",
       "45669       45669  1.618010e+12  58201.78  58245.09  58145.36  58154.87   \n",
       "\n",
       "           Volume    Close_time  Quote_asset_volume  Number_of_trades  \\\n",
       "45660   59.445929  1.618010e+12         3471320.319              3260   \n",
       "45661   97.938052  1.618010e+12         5714994.843              3765   \n",
       "45662  138.791563  1.618010e+12         8087487.627              5370   \n",
       "45663   83.108323  1.618010e+12         4841081.447              3493   \n",
       "45664   84.873621  1.618010e+12         4943439.721              3312   \n",
       "45665  131.702736  1.618010e+12         7660996.206              5248   \n",
       "45666  104.519037  1.618010e+12         6081276.242              4277   \n",
       "45667  100.349232  1.618010e+12         5839902.629              3925   \n",
       "45668   70.695408  1.618010e+12         4117410.120              3204   \n",
       "45669   99.175260  1.618010e+12         5771749.838              3815   \n",
       "\n",
       "       Taker_buy_base_asset_volume  Taker_buy_quote_asset_volume  Unknown  \\\n",
       "45660                    27.469728                   1604075.748        0   \n",
       "45661                    49.064842                   2863136.553        0   \n",
       "45662                    66.534853                   3876654.192        0   \n",
       "45663                    50.694005                   2952965.767        0   \n",
       "45664                    52.779177                   3074098.136        0   \n",
       "45665                    47.561720                   2766511.388        0   \n",
       "45666                    57.195113                   3328089.105        0   \n",
       "45667                    58.730951                   3417842.734        0   \n",
       "45668                    40.784166                   2375271.787        0   \n",
       "45669                    48.699615                   2834077.657        0   \n",
       "\n",
       "                  Datetime  \n",
       "45660  2021-04-08 13:00:00  \n",
       "45661  2021-04-08 13:05:00  \n",
       "45662  2021-04-08 13:10:00  \n",
       "45663  2021-04-08 13:15:00  \n",
       "45664  2021-04-08 13:20:00  \n",
       "45665  2021-04-08 13:25:00  \n",
       "45666  2021-04-08 13:30:00  \n",
       "45667  2021-04-08 13:35:00  \n",
       "45668  2021-04-08 13:40:00  \n",
       "45669  2021-04-08 13:45:00  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_y = df_init.iloc[index-10:index]\n",
    "real_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45648    58322.58\n",
       "45649    58331.66\n",
       "45650    58405.63\n",
       "45651    58410.82\n",
       "45652    58350.99\n",
       "45653    58401.54\n",
       "45654    58413.98\n",
       "45655    58440.67\n",
       "45656    58494.99\n",
       "45657    58468.68\n",
       "45658    58423.86\n",
       "45659    58430.17\n",
       "45660    58376.27\n",
       "45661    58361.24\n",
       "45662    58264.10\n",
       "45663    58232.12\n",
       "45664    58260.49\n",
       "45665    58178.00\n",
       "45666    58200.01\n",
       "45667    58190.72\n",
       "45668    58201.78\n",
       "45669    58154.87\n",
       "45670    58184.58\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "y_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "trend_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "train_x = x_scaler.fit_transform(train_x)\n",
    "test_x = x_scaler.transform(test_x)\n",
    "\n",
    "raw_train_y = train_y.values.reshape(-1, 1)\n",
    "raw_test_y = test_y.values.reshape(-1, 1)\n",
    "train_y = y_scaler.fit_transform(train_y.values.reshape(-1, 1))\n",
    "test_y = y_scaler.transform(test_y.values.reshape(-1, 1))\n",
    "\n",
    "print(type(raw_train_y))\n",
    "print(type(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# For price prediction model\n",
    "train_x_slide, train_y_slide, train_y_gan,train_y_gan_cl,train_direction_slide = sliding_window(train_x, train_y,raw_train_y, sliding_window_size,classification_label_size,trend_measure_lenth)                \n",
    "test_x_slide, test_y_slide, test_y_gan,test_y_gan_cl,test_direction_slide = sliding_window(test_x, test_y, raw_test_y ,sliding_window_size,classification_label_size,trend_measure_lenth)\n",
    "\n",
    "train_trend_features = trend_detection(train_direction_slide)\n",
    "test_trend_features = trend_detection(test_direction_slide)\n",
    "train_trend_features = torch.tensor(trend_scaler.fit_transform(train_trend_features))\n",
    "test_trend_features = torch.tensor(trend_scaler.transform(test_trend_features))\n",
    "new_feature_tensor_train = train_trend_features.repeat(1,10)\n",
    "new_feature_tensor_train = new_feature_tensor_train.unsqueeze(2)\n",
    "new_feature_tensor_test = test_trend_features.repeat(1,10)\n",
    "new_feature_tensor_test = new_feature_tensor_test.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[58376.26985849],\n",
       "       [58361.23988995],\n",
       "       [58264.09977984],\n",
       "       [58232.12016359],\n",
       "       [58260.48986965],\n",
       "       [58177.99991339],\n",
       "       [58200.0102297 ],\n",
       "       [58190.71980673],\n",
       "       [58201.78009927],\n",
       "       [58154.87020192],\n",
       "       [58184.5798407 ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_ac = y_scaler.inverse_transform(test_y_slide)\n",
    "y_test_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def xgboost_test(x,xgmodel):\n",
    "    out_gru_3_xg = x.reshape(x.shape[0], -1)\n",
    "    pred = xgmodel.predict(out_gru_3_xg.detach().cpu().numpy())\n",
    "    pred = torch.tensor(pred).reshape(pred.shape[0],1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelG1 = torch.load(wgan_model_url, map_location=torch.device('cpu'))\n",
    "state_dict = modelG1.state_dict()\n",
    "modelG = Generator(train_x.shape[1])\n",
    "modelG.load_state_dict(state_dict)\n",
    "modelG.eval()\n",
    "\n",
    "model_xgboost = xgb.XGBClassifier()\n",
    "model_xgboost.load_model(xgb_model_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], dtype=torch.int32)\n",
      "[[59408.27 ]\n",
      " [59394.46 ]\n",
      " [59384.746]\n",
      " [59369.25 ]\n",
      " [59360.89 ]\n",
      " [59377.734]\n",
      " [59368.547]\n",
      " [59338.953]\n",
      " [59357.582]\n",
      " [59392.71 ]\n",
      " [59342.094]]\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "price_prediction,test_input_features = modelG(test_x_slide.to(device))\n",
    "test_input_features = torch.cat((test_input_features, new_feature_tensor_test), dim=2)\n",
    "pred_direction_test = xgboost_test(test_input_features,model_xgboost)\n",
    "\n",
    "y_test_true = y_scaler.inverse_transform(price_prediction.detach().numpy())\n",
    "\n",
    "print(pred_direction_test)\n",
    "print(y_test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], dtype=torch.int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_direction_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59408.27 ]\n",
      " [59394.46 ]\n",
      " [59384.746]\n",
      " [59369.25 ]\n",
      " [59360.89 ]\n",
      " [59377.734]\n",
      " [59368.547]\n",
      " [59338.953]\n",
      " [59357.582]\n",
      " [59392.71 ]\n",
      " [59342.094]]\n",
      "\n",
      "       Unnamed: 0     Open_time      Open      High       Low     Close  \\\n",
      "45660       45660  1.618010e+12  58430.16  58430.17  58368.04  58376.27   \n",
      "45661       45661  1.618010e+12  58376.28  58385.42  58321.74  58361.24   \n",
      "45662       45662  1.618010e+12  58361.24  58361.24  58201.30  58264.10   \n",
      "45663       45663  1.618010e+12  58264.10  58294.88  58211.00  58232.12   \n",
      "45664       45664  1.618010e+12  58232.13  58272.15  58229.30  58260.49   \n",
      "45665       45665  1.618010e+12  58260.48  58262.80  58105.22  58178.00   \n",
      "45666       45666  1.618010e+12  58178.00  58225.93  58128.21  58200.01   \n",
      "45667       45667  1.618010e+12  58200.00  58229.06  58149.24  58190.72   \n",
      "45668       45668  1.618010e+12  58190.72  58278.53  58190.72  58201.78   \n",
      "45669       45669  1.618010e+12  58201.78  58245.09  58145.36  58154.87   \n",
      "\n",
      "           Volume    Close_time  Quote_asset_volume  Number_of_trades  \\\n",
      "45660   59.445929  1.618010e+12         3471320.319              3260   \n",
      "45661   97.938052  1.618010e+12         5714994.843              3765   \n",
      "45662  138.791563  1.618010e+12         8087487.627              5370   \n",
      "45663   83.108323  1.618010e+12         4841081.447              3493   \n",
      "45664   84.873621  1.618010e+12         4943439.721              3312   \n",
      "45665  131.702736  1.618010e+12         7660996.206              5248   \n",
      "45666  104.519037  1.618010e+12         6081276.242              4277   \n",
      "45667  100.349232  1.618010e+12         5839902.629              3925   \n",
      "45668   70.695408  1.618010e+12         4117410.120              3204   \n",
      "45669   99.175260  1.618010e+12         5771749.838              3815   \n",
      "\n",
      "       Taker_buy_base_asset_volume  Taker_buy_quote_asset_volume  Unknown  \\\n",
      "45660                    27.469728                   1604075.748        0   \n",
      "45661                    49.064842                   2863136.553        0   \n",
      "45662                    66.534853                   3876654.192        0   \n",
      "45663                    50.694005                   2952965.767        0   \n",
      "45664                    52.779177                   3074098.136        0   \n",
      "45665                    47.561720                   2766511.388        0   \n",
      "45666                    57.195113                   3328089.105        0   \n",
      "45667                    58.730951                   3417842.734        0   \n",
      "45668                    40.784166                   2375271.787        0   \n",
      "45669                    48.699615                   2834077.657        0   \n",
      "\n",
      "                  Datetime  \n",
      "45660  2021-04-08 13:00:00  \n",
      "45661  2021-04-08 13:05:00  \n",
      "45662  2021-04-08 13:10:00  \n",
      "45663  2021-04-08 13:15:00  \n",
      "45664  2021-04-08 13:20:00  \n",
      "45665  2021-04-08 13:25:00  \n",
      "45666  2021-04-08 13:30:00  \n",
      "45667  2021-04-08 13:35:00  \n",
      "45668  2021-04-08 13:40:00  \n",
      "45669  2021-04-08 13:45:00  \n",
      "\n",
      "tensor([0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import grad as torch_grad\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.misc import derivative\n",
    "\n",
    "def sliding_window(x, y, y_raw ,feature_window,label_window,trend_window):\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "    y_gan_pr = []\n",
    "    y_gan_cl = []\n",
    "    y_gan_tr = []\n",
    "    backward_length = max(trend_window,label_window)\n",
    "    for i in range(backward_length, x.shape[0]-label_window):\n",
    "        tmp_x = x[i - feature_window: i, :]\n",
    "        tmp_y = y[i]\n",
    "        tmp_y_gan_pr = y[i - feature_window: i + 1]\n",
    "        tmp_y_gan_cl = y_raw[i - label_window: i + label_window+1]\n",
    "        tmp_y_gan_tr = y_raw[i - trend_window: i, :]\n",
    "        x_.append(tmp_x)\n",
    "        y_.append(tmp_y)\n",
    "        y_gan_pr.append(tmp_y_gan_pr)\n",
    "        y_gan_cl.append(tmp_y_gan_cl)\n",
    "        y_gan_tr.append(tmp_y_gan_tr)\n",
    "    x_ = torch.from_numpy(np.array(x_)).float()\n",
    "    y_ = torch.from_numpy(np.array(y_)).float()\n",
    "    # print(y_gan_cl.shape)\n",
    "    # print(type(y_gan_cl))\n",
    "    y_gan_pr = torch.from_numpy(np.array(y_gan_pr)).float()\n",
    "    y_gan_cl = np.array(y_gan_cl)\n",
    "    y_gan_cl = y_gan_cl.astype(np.float64)\n",
    "    y_gan_cl = torch.from_numpy(np.array(y_gan_cl)).float()\n",
    "    y_gan_tr = np.array(y_gan_tr)\n",
    "    y_gan_tr = y_gan_tr.astype(np.float64)\n",
    "    y_gan_tr = torch.from_numpy(np.array(y_gan_tr)).float()\n",
    "    return x_, y_, y_gan_pr,y_gan_cl,y_gan_tr\n",
    "\n",
    "def trend_detection(data):\n",
    "    n = data.shape[1]\n",
    "    sets = data.shape[0]\n",
    "    mean_derivatives = np.zeros((sets, 1))\n",
    "\n",
    "    for i in range(sets):\n",
    "        x = np.arange(1, n + 1)\n",
    "        x_fake = np.arange(1.1, n, 0.1)\n",
    "        y = data[i, :, 0]\n",
    "\n",
    "        # Linear interpolation of x and y\n",
    "        f = np.interp(x_fake, x, y)\n",
    "\n",
    "        # Calculate the derivatives\n",
    "        df_dx = np.gradient(f, x_fake)\n",
    "\n",
    "        # Calculate the mean derivative for the i-th set\n",
    "        average = np.average(df_dx)\n",
    "        mean_derivatives[i][0] = average\n",
    "\n",
    "    return torch.from_numpy(mean_derivatives)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # 3 GRU layers, input_size = features\n",
    "        self.gru_1 = nn.GRU(input_size, 1024, batch_first=True)\n",
    "        self.gru_2 = nn.GRU(1024, 512, batch_first = True)\n",
    "        self.gru_3 = nn.GRU(512, 256, batch_first = True)\n",
    "        # 3 Dense Layers\n",
    "        self.linear_1 = nn.Linear(256, 128)\n",
    "        self.linear_2 = nn.Linear(128, 64)\n",
    "        self.linear_3 = nn.Linear(64, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x,use_cuda=0):\n",
    "        h0 = torch.zeros(1, x.size(0), 1024) # initial hidden state for the 1st GRU Layer - (num of layers in the GRU, batch size, num of hidden units in the GRU)\n",
    "        out_gru_1, _ = self.gru_1(x, h0)\n",
    "        out_gru_1 = self.dropout(out_gru_1)\n",
    "\n",
    "        h1 = torch.zeros(1, x.size(0), 512)\n",
    "        out_gru_2, _ = self.gru_2(out_gru_1, h1)\n",
    "        out_gru_2 = self.dropout(out_gru_2)\n",
    "\n",
    "        h2 = torch.zeros(1, x.size(0), 256)\n",
    "        out_gru_3, _ = self.gru_3(out_gru_2, h2)\n",
    "        out_gru_3 = self.dropout(out_gru_3)\n",
    "\n",
    "        out_dense_1 = self.linear_1(out_gru_3[:, -1, :])\n",
    "        out_dense_2 = self.linear_2(out_dense_1)\n",
    "        out_dense_3 = self.linear_3(out_dense_2)\n",
    "\n",
    "        return out_dense_3,out_gru_3\n",
    "    \n",
    "def xgboost_test(x,xgmodel):\n",
    "    out_gru_3_xg = x.reshape(x.shape[0], -1)\n",
    "    pred = xgmodel.predict(out_gru_3_xg.detach().cpu().numpy())\n",
    "    pred = torch.tensor(pred).reshape(pred.shape[0],1)\n",
    "    return pred    \n",
    "\n",
    "#Constants    \n",
    "starting_index = 0\n",
    "testing_duration = 22\n",
    "sliding_window_size = 10\n",
    "trend_measure_lenth = 12\n",
    "training_duration = 4032\n",
    "train_offset = 8640*4+4032\n",
    "classification_label_size = 0\n",
    "device = 'cpu'\n",
    "\n",
    "def get_prediction(timestamp, asset):\n",
    "    \n",
    "    if asset == \"BTC\":\n",
    "        df_init = pd.read_csv(\"dataset/initial/btc_init.csv\")\n",
    "        df = pd.read_csv(\"dataset/preprocessed/btc_pca.csv\")\n",
    "        wgan_model_url = \"trained_models/wgan/wgan_btc.pth\"\n",
    "        xgb_model_url = \"trained_models/bottom/BPC_WGAN_BTC.model\"\n",
    "\n",
    "    elif asset == \"ETH\":\n",
    "        df_init = pd.read_csv(\"dataset/initial/eth_init.csv\")\n",
    "        df = pd.read_csv(\"dataset/preprocessed/eth_pca.csv\")\n",
    "        wgan_model_url = \"trained_models/wgan/wgan_eth.pth\"\n",
    "        xgb_model_url = \"trained_models/bottom/BPC_WGAN_ETH.model\"\n",
    "\n",
    "    elif asset == \"LTC\":\n",
    "        df_init = pd.read_csv(\"dataset/initial/ltc_init.csv\")\n",
    "        df = pd.read_csv(\"dataset/preprocessed/ltc_pca.csv\")\n",
    "        wgan_model_url = \"trained_models/wgan/wgan_ltc.pth\"\n",
    "        xgb_model_url = \"trained_models/bottom/BPC_WGAN_LTC.model\"\n",
    "\n",
    "    elif asset == \"AAPL\":\n",
    "        df_init = pd.read_csv(\"dataset/initial/aapl_init.csv\")\n",
    "        df = pd.read_csv(\"dataset/preprocessed/aapl_pca.csv\")\n",
    "        wgan_model_url = \"trained_models/wgan/wgan_aapl.pth\"\n",
    "        xgb_model_url = \"trained_models/bottom/BPC_WGAN_AAPL.model\"\n",
    "\n",
    "    elif asset == \"TSLA\":\n",
    "        df_init = pd.read_csv(\"dataset/initial/tsla_init.csv\")\n",
    "        df = pd.read_csv(\"dataset/preprocessed/tsla_pca.csv\")\n",
    "        wgan_model_url = \"trained_models/wgan/wgan_tsla.pth\"\n",
    "        xgb_model_url = \"trained_models/bottom/BPC_WGAN_TSLA.model\"\n",
    "\n",
    "    elif asset == \"SBUX\":\n",
    "        df_init = pd.read_csv(\"dataset/initial/sbux_init.csv\")\n",
    "        df = pd.read_csv(\"dataset/preprocessed/sbux_pca.csv\")\n",
    "        wgan_model_url = \"trained_models/wgan/wgan_sbux.pth\"\n",
    "        xgb_model_url = \"trained_models/bottom/BPC_WGAN_SBUX.model\"\n",
    "    \n",
    "    # Index of the required timestep\n",
    "    index = df_init[df_init['Datetime'] == timestamp].index.item()\n",
    "    \n",
    "    # Train test split\n",
    "    labels_df = df[\"Close\"]\n",
    "    features_df = df.drop(columns=[\"Close\"])\n",
    "    train_x = features_df.iloc[train_offset:train_offset+training_duration]\n",
    "    train_y = labels_df.iloc[train_offset:train_offset+training_duration]\n",
    "    test_x = features_df.iloc[index-testing_duration:index+1]\n",
    "    test_y = labels_df.iloc[index-testing_duration:index+1]\n",
    "    \n",
    "    # Scaling the Dataset \n",
    "    x_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    y_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    trend_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    train_x = x_scaler.fit_transform(train_x)\n",
    "    test_x = x_scaler.transform(test_x)\n",
    "    raw_train_y = train_y.values.reshape(-1, 1)\n",
    "    raw_test_y = test_y.values.reshape(-1, 1)\n",
    "    train_y = y_scaler.fit_transform(train_y.values.reshape(-1, 1))\n",
    "    test_y = y_scaler.transform(test_y.values.reshape(-1, 1))\n",
    "    \n",
    "    # Input data preprocess\n",
    "    train_x_slide, train_y_slide, train_y_gan,train_y_gan_cl,train_direction_slide = sliding_window(train_x, train_y,raw_train_y, sliding_window_size,classification_label_size,trend_measure_lenth)                \n",
    "    test_x_slide, test_y_slide, test_y_gan,test_y_gan_cl,test_direction_slide = sliding_window(test_x, test_y, raw_test_y ,sliding_window_size,classification_label_size,trend_measure_lenth)\n",
    "    train_trend_features = trend_detection(train_direction_slide)\n",
    "    test_trend_features = trend_detection(test_direction_slide)\n",
    "    train_trend_features = torch.tensor(trend_scaler.fit_transform(train_trend_features))\n",
    "    test_trend_features = torch.tensor(trend_scaler.transform(test_trend_features))\n",
    "    new_feature_tensor_train = train_trend_features.repeat(1,10)\n",
    "    new_feature_tensor_train = new_feature_tensor_train.unsqueeze(2)\n",
    "    new_feature_tensor_test = test_trend_features.repeat(1,10)\n",
    "    new_feature_tensor_test = new_feature_tensor_test.unsqueeze(2)\n",
    "    \n",
    "    modelG1 = torch.load(wgan_model_url, map_location=torch.device('cpu'))\n",
    "    state_dict = modelG1.state_dict()\n",
    "    modelG2 = Generator(train_x.shape[1])\n",
    "    modelG2.load_state_dict(state_dict)\n",
    "    modelG2.eval()\n",
    "    \n",
    "    model_xgboost = xgb.XGBClassifier()\n",
    "    model_xgboost.load_model(xgb_model_url)\n",
    "    \n",
    "    price_prediction,test_input_features = modelG2(test_x_slide)\n",
    "    test_input_features = torch.cat((test_input_features, new_feature_tensor_test), dim=2)\n",
    "    pred_direction_test = xgboost_test(test_input_features,model_xgboost)\n",
    "\n",
    "    # predicted 11 steps\n",
    "    y_test_pred = y_scaler.inverse_transform(price_prediction.detach().numpy())\n",
    "    # Actuall 10 steps\n",
    "    real_y = df_init.iloc[index-10:index]\n",
    "    # Predicted bottom for timestep 11\n",
    "    bottom_point = pred_direction_test[-1]\n",
    "    print(y_test_pred)\n",
    "    print()\n",
    "    print(real_y)\n",
    "    print()\n",
    "    print(bottom_point)\n",
    "\n",
    "asset = \"BTC\"\n",
    "timestamp = \"2021-04-08 13:50:00\"    \n",
    "get_prediction(timestamp,asset)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "description": null,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "save_output": true,
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
